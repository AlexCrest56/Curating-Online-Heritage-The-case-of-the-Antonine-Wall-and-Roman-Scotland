install.packages("academictwitteR")
install.packages("tidyverse")
library(academictwitteR)
library(jsonlite)
library(tidyverse)
library(dplyr)
library(stringr)


# Set bearer token. This is the one copied from the Developer Academic twitter portal
bearer_token <-"---"


#Tweets
Data_Antonine_Wall <- get_all_tweets(
"antonine wall",
"2006-07-15T00:00:00Z",
"2022-11-09T00:00:00Z",
bearer_token,
bind_tweets = TRUE,
n = 1000000)


#USER Profiles
# Create a list of each of the dataframe's author_id's, and run a line of code
#for each
Users_List_Antonine_Wall <- (Data_Antonine_Wall$author_id)
Users_Data_Antonine_Wall <- get_user_profile(Users_List_Antonine_Wall, bearer_token)

#Merging these with tweet dataframes
#First, rename several columns in User_Data frames that have the same name as tweet data, but refer to different things, and to allow for merging.
Users_Data_Antonine_Wall_Joinable <- Users_Data_Antonine_Wall %>%
rename(author_id = id)
Users_Data_Antonine_Wall_Joinable <- Users_Data_Antonine_Wall_Joinable %>%
rename(account_created = created_at)

CombData_Antonine_Wall <- full_join(Data_Antonine_Wall, Users_Data_Antonine_Wall_Joinable, by = 'author_id')
CombData_Antonine_Wall <- CombData_Antonine_Wall[!duplicated(CombData_Antonine_Wall$id),]

#Write as json
Twitter_data <- toJSON(CombData_Antonine_Wall, pretty = TRUE)

#I don't need these columns
possibly_sensitive
edit_history_tweet_ids
protected
profile_image_url

# delete columns
Twitter_data <- Twitter_data %>% select(-possibly_sensitive, -edit_history_tweet_ids, -protected, -profile_image_url)


# add codes
Twitter_data <- Twitter_data %>% mutate(Code = paste0("TW.", seq_len(nrow(Twitter_data))))

#Now anonymising data in the following columns
# add author_codes column
#author_id - delete
#name - delete 
#text  -swap out mentions with 'Mention' to indicate where there would have been one. (add 'Mention' to topic modelling stopwords later)
#in_reply_to_user_id - delete (I don't need the mentions for this study. Network analysis not required)
#username - delete
#entitiesx$mentions - delete

# Step 1: Identify unique authors
unique_authors <- unique(Twitter_data$author_id)

# Step 2: Generate a sequence of codes for these authors
author_codes <- paste0("TW.Auth.", seq_along(unique_authors))

# Step 3: Create a mapping from unique authors to their codes
author_code_mapping <- setNames(author_codes, unique_authors)

# Apply the mapping to create a new column in the dataframe
Twitter_data$Author_Code <- author_code_mapping[Twitter_data$author_id]

#Removing the name column
Twitter_data <- Twitter_data %>% select(-name)

## anonymise mentions in text, repalcing them with "@Mention"
Twitter_data <- Twitter_data %>%
  mutate(text = str_replace_all(text, "@\\w+", "@Mention"))

Codes_Names_AuthIds  <- cbind(Twitter_data$Author_Code, Twitter_data$username, Twitter_data$author_id)
  

# deleting all spare columns
Twitter_data <- Twitter_data %>% select(-entities.x, -author_id , -name, -in_reply_to_user_id, -username)

#save and to database
write(Twitter_data, path = "Twitter_data.json", pretty = TRUE)

conn <- mongo(collection = "Twitter_Anon", url = "mongodb://localhost:27017/Antonine_Wall_Value_Assemblages")

conn$insert(Twitter_data)
